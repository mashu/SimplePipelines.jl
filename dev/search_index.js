var documenterSearchIndex = {"docs":
[{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api/#Types","page":"API Reference","title":"Types","text":"","category":"section"},{"location":"api/#Macros","page":"API Reference","title":"Macros","text":"","category":"section"},{"location":"api/#Operators","page":"API Reference","title":"Operators","text":"","category":"section"},{"location":"api/#Execution","page":"API Reference","title":"Execution","text":"","category":"section"},{"location":"api/#Utilities","page":"API Reference","title":"Utilities","text":"","category":"section"},{"location":"api/#Index","page":"API Reference","title":"Index","text":"","category":"section"},{"location":"api/#SimplePipelines.AbstractNode","page":"API Reference","title":"SimplePipelines.AbstractNode","text":"AbstractNode\n\nBase type for all pipeline nodes. Subtypes are:\n\nStep: A single unit of work\nSequence: Nodes that run in order\nParallel: Nodes that run concurrently\n\n\n\n\n\n","category":"type"},{"location":"api/#SimplePipelines.Step","page":"API Reference","title":"SimplePipelines.Step","text":"Step{F}\n\nA single unit of work in the pipeline.\n\nType Parameters\n\nF: The type of work (e.g., Cmd for shell commands, or a Function subtype)\n\nFields\n\nname::Symbol: Identifier for the step\nwork::F: The work to execute\ninputs::Vector{String}: Input file dependencies (optional)\noutputs::Vector{String}: Output files produced (optional)\n\nExamples\n\n# Shell command\nStep(:align, `bwa mem ref.fa reads.fq`)\n\n# Julia function\nStep(:qc, () -> run_quality_control())\n\n# With file dependencies\nStep(:variant_call, `bcftools call -m aligned.bam`, [\"aligned.bam\"], [\"variants.vcf\"])\n\n\n\n\n\n","category":"type"},{"location":"api/#SimplePipelines.Sequence","page":"API Reference","title":"SimplePipelines.Sequence","text":"Sequence{T<:Tuple}\n\nA sequence of nodes that execute in order. The type parameter T captures the exact tuple type for full type stability.\n\nExamples\n\n# Created via >> operator\nalign >> sort >> index\n\n\n\n\n\n","category":"type"},{"location":"api/#SimplePipelines.Parallel","page":"API Reference","title":"SimplePipelines.Parallel","text":"Parallel{T<:Tuple}\n\nNodes that execute concurrently. The type parameter T captures the exact tuple type for full type stability.\n\nExamples\n\n# Created via & operator\n(sample_a & sample_b & sample_c) >> merge\n\n\n\n\n\n","category":"type"},{"location":"api/#SimplePipelines.Pipeline","page":"API Reference","title":"SimplePipelines.Pipeline","text":"Pipeline{N<:AbstractNode}\n\nA complete pipeline ready for execution.\n\nFields\n\nroot::N: The root node of the pipeline DAG\nname::String: Human-readable name for the pipeline\n\nExamples\n\n# Create from composed nodes\np = Pipeline(align >> sort >> index, name=\"alignment\")\n\n# Or wrap multiple nodes (creates a Sequence)\np = Pipeline(step1, step2, step3)\n\n\n\n\n\n","category":"type"},{"location":"api/#SimplePipelines.@step","page":"API Reference","title":"SimplePipelines.@step","text":"@step expr\n@step name = expr\n@step name(inputs => outputs) = expr\n\nCreate a Step with optional name and file dependencies.\n\nExamples\n\n# Anonymous step\n@step `fastqc sample.fq`\n\n# Named step\n@step align = `bwa mem ref.fa reads.fq > aligned.sam`\n\n# With file dependencies (for dependency tracking)\n@step sort(\"aligned.sam\" => \"sorted.bam\") = `samtools sort aligned.sam`\n\n# Julia function\n@step qc_report = generate_multiqc_report\n\n\n\n\n\n","category":"macro"},{"location":"api/#Base.:>>","page":"API Reference","title":"Base.:>>","text":"a >> b\n\nCreate a Sequence where a completes before b starts.\n\nSupports chaining: a >> b >> c creates a single flattened sequence.\n\nExamples\n\n# Basic sequence\nfastqc >> trim >> align\n\n# Chain shell commands directly\n`fastqc raw.fq` >> `trimmomatic ...` >> `bwa mem ...`\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.:&","page":"API Reference","title":"Base.:&","text":"a & b\n\nCreate a Parallel where a and b run concurrently.\n\nSupports chaining: a & b & c creates a single parallel group.\n\nExamples\n\n# Process multiple samples in parallel\n(sample1 & sample2 & sample3) >> merge_results\n\n# Mix with sequences for complex DAGs\n(trim_a >> align_a) & (trim_b >> align_b) >> joint_call\n\n\n\n\n\n","category":"function"},{"location":"api/#SimplePipelines.run_pipeline","page":"API Reference","title":"SimplePipelines.run_pipeline","text":"run_pipeline(p::Pipeline; verbose=true, dry_run=false)\nrun_pipeline(node::AbstractNode; verbose=true, dry_run=false)\n\nExecute a pipeline or node.\n\nArguments\n\nverbose::Bool=true: Print progress information\ndry_run::Bool=false: Show DAG structure without executing\n\nReturns\n\nVector{StepResult}: Results from all executed steps\n\nExamples\n\n# Run with progress output\nresults = run_pipeline(pipeline)\n\n# Silent execution\nresults = run_pipeline(pipeline, verbose=false)\n\n# Preview structure\nrun_pipeline(pipeline, dry_run=true)\n\n\n\n\n\n","category":"function"},{"location":"api/#SimplePipelines.count_steps","page":"API Reference","title":"SimplePipelines.count_steps","text":"count_steps(node::AbstractNode) -> Int\n\nCount total steps in a pipeline node.\n\n\n\n\n\n","category":"function"},{"location":"api/#SimplePipelines.steps","page":"API Reference","title":"SimplePipelines.steps","text":"steps(node::AbstractNode) -> Vector{Step}\n\nFlatten all steps from a pipeline node into a vector.\n\n\n\n\n\n","category":"function"},{"location":"api/#SimplePipelines.print_dag","page":"API Reference","title":"SimplePipelines.print_dag","text":"print_dag(node; indent=0)\n\nPrint the DAG structure of a pipeline node.\n\nExamples\n\npipeline = (a & b) >> c >> (d & e)\nprint_dag(pipeline)\n# Output:\n# Sequence:\n#   Parallel:\n#     a\n#     b\n#   c\n#   Parallel:\n#     d\n#     e\n\n\n\n\n\n","category":"function"},{"location":"design/#Design","page":"Design","title":"Design","text":"","category":"section"},{"location":"design/#Interface-Overview","page":"Design","title":"Interface Overview","text":"┌─────────────────────────────────────────────────────────────┐\n│                    SimplePipelines.jl                       │\n├─────────────────────────────────────────────────────────────┤\n│                                                             │\n│  @step name = `command`     Create a shell step             │\n│  @step name = () -> ...     Create a Julia step             │\n│                                                             │\n│  a >> b                     Sequential: a then b            │\n│  a & b                      Parallel: a and b together      │\n│                                                             │\n│  run_pipeline(p)            Execute the pipeline            │\n│                                                             │\n└─────────────────────────────────────────────────────────────┘","category":"section"},{"location":"design/#Type-Hierarchy","page":"Design","title":"Type Hierarchy","text":"AbstractNode\n    │\n    ├── Step{F}           Single unit of work\n    │                     F = Cmd | Function\n    │\n    ├── Sequence{T}       Sequential execution\n    │                     T = Tuple of nodes\n    │\n    └── Parallel{T}       Concurrent execution\n                          T = Tuple of nodes\n\nAll types are fully parametric—the compiler knows exact types at every level.","category":"section"},{"location":"design/#Composition-Model","page":"Design","title":"Composition Model","text":"# User writes:\n`echo a` >> (`echo b` & `echo c`) >> `echo d`\n\n# Becomes:\nSequence{Tuple{\n    Step{Cmd},\n    Parallel{Tuple{Step{Cmd}, Step{Cmd}}},\n    Step{Cmd}\n}}\n\nThe complete structure is encoded in the type, enabling full compile-time specialization.","category":"section"},{"location":"design/#Execution-Flow","page":"Design","title":"Execution Flow","text":"run_pipeline(Pipeline)\n       │\n       ▼\nrun_node(root, verbosity)  ─── dispatches on node type\n       │\n       ├─► Step:     execute(step) → StepResult\n       │\n       ├─► Sequence: run first node, then recurse on rest\n       │\n       └─► Parallel: @spawn all nodes, fetch all results","category":"section"},{"location":"design/#Key-Design-Decisions","page":"Design","title":"Key Design Decisions","text":"","category":"section"},{"location":"design/#1.-Tuples,-Not-Vectors","page":"Design","title":"1. Tuples, Not Vectors","text":"# ✗ Vector: type information lost\nSequence(nodes::Vector{AbstractNode})\n\n# ✓ Tuple: exact types preserved\nSequence{Tuple{Step{Cmd}, Step{Function}}}\n\nTuples enable the compiler to generate specialized code for each node.","category":"section"},{"location":"design/#2.-Multiple-Dispatch,-Not-Type-Checks","page":"Design","title":"2. Multiple Dispatch, Not Type Checks","text":"# ✗ Runtime type checking (type unstable)\nfunction run_node(node)\n    if node isa Step\n        # ...\n    elseif node isa Sequence\n        # ...\n    end\nend\n\n# ✓ Multiple dispatch (type stable)\nrun_node(step::Step, v) = execute(step)\nrun_node(seq::Sequence, v) = _run_sequence!([], seq.nodes, v)\nrun_node(par::Parallel, v) = _spawn_parallel(par.nodes, v)","category":"section"},{"location":"design/#3.-Tuple-Recursion","page":"Design","title":"3. Tuple Recursion","text":"Iterate tuples in a type-stable way:\n\n# Base case\n_run_sequence!(results, ::Tuple{}, v) = nothing\n\n# Recursive case\nfunction _run_sequence!(results, nodes::Tuple, v)\n    append!(results, run_node(first(nodes), v))\n    _run_sequence!(results, Base.tail(nodes), v)\nend\n\nThe compiler unrolls this into efficient, specialized code.","category":"section"},{"location":"design/#4.-Verbosity-as-Types","page":"Design","title":"4. Verbosity as Types","text":"struct Verbose end\nstruct Silent end\n\nprint_start(::Silent, ::Step) = nothing\nprint_start(::Verbose, s::Step) = println(\"▶ $(s.name)\")\n\nDead code elimination removes printing when verbose=false.","category":"section"},{"location":"design/#Performance-Characteristics","page":"Design","title":"Performance Characteristics","text":"Aspect Design Choice Benefit\nNode storage Tuples Full type info, inline storage\nDispatch Multiple dispatch Zero runtime type checks\nIteration Recursion Compiler unrolling\nOperators @inline Zero call overhead\nVerbosity Singleton types Dead code elimination","category":"section"},{"location":"examples/#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/#Basic-Pipeline","page":"Examples","title":"Basic Pipeline","text":"A simple three-step workflow:\n\nusing SimplePipelines\n\ndownload = @step download = `curl -o data.txt https://example.com/data`\nprocess = @step process = `sort data.txt > sorted.txt`\nupload = @step upload = `scp sorted.txt server:/data/`\n\npipeline = download >> process >> upload\nrun_pipeline(pipeline)","category":"section"},{"location":"examples/#Parallel-Processing","page":"Examples","title":"Parallel Processing","text":"Process multiple files concurrently:\n\nusing SimplePipelines\n\n# Process each file independently\nfile_a = @step a = `gzip -k file_a.txt`\nfile_b = @step b = `gzip -k file_b.txt`\nfile_c = @step c = `gzip -k file_c.txt`\n\n# Archive all compressed files\narchive = @step archive = `tar -cvf archive.tar *.gz`\n\n# Files compress in parallel, then archive\npipeline = (file_a & file_b & file_c) >> archive\nrun_pipeline(pipeline)","category":"section"},{"location":"examples/#Julia-Computation","page":"Examples","title":"Julia Computation","text":"Mix Julia computation with external tools:\n\nusing SimplePipelines\n\n# Generate data in Julia\ngenerate = @step generate = () -> begin\n    data = rand(1000, 100)\n    writedlm(\"matrix.csv\", data, ',')\n    return \"Generated $(size(data)) matrix\"\nend\n\n# Process with external tool\nprocess = @step process = `./analyze matrix.csv -o stats.json`\n\n# Load and report in Julia\nreport = @step report = () -> begin\n    stats = JSON.parsefile(\"stats.json\")\n    println(\"Mean: $(stats[\"mean\"])\")\n    println(\"Std:  $(stats[\"std\"])\")\nend\n\npipeline = generate >> process >> report\nrun_pipeline(pipeline)","category":"section"},{"location":"examples/#Bioinformatics:-NGS-Alignment","page":"Examples","title":"Bioinformatics: NGS Alignment","text":"A typical next-generation sequencing alignment workflow:\n\nusing SimplePipelines\n\n# Quality control\nfastqc = @step fastqc = `fastqc -o qc/ reads.fq.gz`\n\n# Trim adapters\ntrim = @step trim = `trimmomatic SE reads.fq.gz trimmed.fq.gz ILLUMINACLIP:adapters.fa:2:30:10`\n\n# Align to reference\nalign = @step align = `bwa mem -t 8 reference.fa trimmed.fq.gz > aligned.sam`\n\n# Convert and sort\nsort_bam = @step sort = `samtools sort -@ 4 -o sorted.bam aligned.sam`\n\n# Index\nindex = @step index = `samtools index sorted.bam`\n\n# Full pipeline\npipeline = fastqc >> trim >> align >> sort_bam >> index\nrun_pipeline(Pipeline(pipeline, name=\"NGS Alignment\"))","category":"section"},{"location":"examples/#Bioinformatics:-Multi-Sample-Variant-Calling","page":"Examples","title":"Bioinformatics: Multi-Sample Variant Calling","text":"Process multiple samples in parallel, then joint-call variants:\n\nusing SimplePipelines\n\n# Per-sample processing function\nfunction sample_pipeline(name, fastq)\n    trim = Step(Symbol(\"trim_\", name), `trimmomatic SE $fastq $(name)_trimmed.fq.gz ...`)\n    align = Step(Symbol(\"align_\", name), `bwa mem ref.fa $(name)_trimmed.fq.gz > $(name).bam`)\n    sort = Step(Symbol(\"sort_\", name), `samtools sort -o $(name)_sorted.bam $(name).bam`)\n    return trim >> align >> sort\nend\n\n# Build per-sample pipelines\nsample_a = sample_pipeline(\"A\", \"sample_A.fq.gz\")\nsample_b = sample_pipeline(\"B\", \"sample_B.fq.gz\")\nsample_c = sample_pipeline(\"C\", \"sample_C.fq.gz\")\n\n# Joint variant calling (after all samples)\ncall = @step call = `bcftools mpileup -f ref.fa *_sorted.bam | bcftools call -mv -o variants.vcf`\n\n# Filter variants\nfilter_vcf = @step filter = `bcftools filter -e 'QUAL<20' variants.vcf > filtered.vcf`\n\n# Complete pipeline:\n#   (A & B & C) >> call >> filter\npipeline = (sample_a & sample_b & sample_c) >> call >> filter_vcf\n\nrun_pipeline(Pipeline(pipeline, name=\"Multi-Sample Variant Calling\"))","category":"section"},{"location":"examples/#Complex-DAG","page":"Examples","title":"Complex DAG","text":"A workflow with multiple parallel stages:\n\nusing SimplePipelines\n\n# Stage 1: Fetch from multiple sources (parallel)\nfetch_db = @step db = `curl -o db_data.json https://api.database.com/export`\nfetch_files = @step files = `rsync -av server:/data/ local_data/`\n\n# Stage 2: Transform each source (parallel, after fetch)\ntransform_db = @step transform_db = () -> transform_database(\"db_data.json\")\ntransform_files = @step transform_files = () -> transform_files(\"local_data/\")\n\n# Stage 3: Merge and analyze (sequential)\nmerge = @step merge = () -> merge_datasets(\"transformed_db.csv\", \"transformed_files.csv\")\nanalyze = @step analyze = `./analysis_tool merged.csv -o results/`\n\n# Stage 4: Generate outputs (parallel)\nreport = @step report = () -> generate_report(\"results/\")\narchive = @step archive = `tar -czvf results.tar.gz results/`\n\n# Build DAG:\n#   (fetch_db >> transform_db) & (fetch_files >> transform_files)\n#   >> merge >> analyze\n#   >> (report & archive)\n\ndb_branch = fetch_db >> transform_db\nfiles_branch = fetch_files >> transform_files\n\npipeline = (db_branch & files_branch) >> merge >> analyze >> (report & archive)\n\n# Preview structure\nprintln(\"Pipeline structure:\")\nprint_dag(pipeline)\n\n# Execute\nrun_pipeline(pipeline)","category":"section"},{"location":"#SimplePipelines.jl","page":"Home","title":"SimplePipelines.jl","text":"Minimal, type-stable DAG pipelines for Julia","category":"section"},{"location":"#Interface","page":"Home","title":"Interface","text":"┌─────────────────────────────────────────────────────────────┐\n│                    SimplePipelines.jl                       │\n├─────────────────────────────────────────────────────────────┤\n│                                                             │\n│  @step name = `command`       Create a shell step           │\n│  @step name = () -> expr      Create a Julia step           │\n│                                                             │\n│  a >> b                       Sequential: a then b          │\n│  a & b                        Parallel: a and b together    │\n│                                                             │\n│  run_pipeline(pipeline)       Execute the pipeline          │\n│                                                             │\n└─────────────────────────────────────────────────────────────┘","category":"section"},{"location":"#Overview","page":"Home","title":"Overview","text":"SimplePipelines.jl lets you define and execute directed acyclic graph (DAG) pipelines using two operators:\n\nOperator Meaning Example\n>> Sequential (a then b) download >> process >> upload\n& Parallel (a and b together) sample_a & sample_b & sample_c","category":"section"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"using SimplePipelines\n\n# Simple sequence\npipeline = `echo \"step 1\"` >> `echo \"step 2\"` >> `echo \"step 3\"`\nrun_pipeline(pipeline)\n\n# Parallel branches that merge\npipeline = (`process A` & `process B`) >> `merge`\nrun_pipeline(pipeline)","category":"section"},{"location":"#DAG-Patterns","page":"Home","title":"DAG Patterns","text":"","category":"section"},{"location":"#Diamond-(fork-join)","page":"Home","title":"Diamond (fork-join)","text":"       ┌── step_b ──┐\nstep_a─┤            ├── step_d\n       └── step_c ──┘\n\npipeline = step_a >> (step_b & step_c) >> step_d","category":"section"},{"location":"#Multi-stage-parallel","page":"Home","title":"Multi-stage parallel","text":"       ┌─ b ─┐     ┌─ e ─┐\n    a ─┤     ├─ d ─┤     ├─ g\n       └─ c ─┘     └─ f ─┘\n\npipeline = a >> (b & c) >> d >> (e & f) >> g","category":"section"},{"location":"#Independent-branches-merging","page":"Home","title":"Independent branches merging","text":"    ┌─ a ── b ─┐\n    │          │\n    ├─ c ── d ─┼── merge\n    │          │\n    └─ e ── f ─┘\n\nbranch1 = a >> b\nbranch2 = c >> d\nbranch3 = e >> f\n\npipeline = (branch1 & branch2 & branch3) >> merge","category":"section"},{"location":"#Features","page":"Home","title":"Features","text":"Two operators - >> for sequence, & for parallel\nType-stable - Zero runtime type checks, full compile-time specialization\nMinimal overhead - @inline functions and tuple recursion\nUnified interface - Shell commands and Julia functions compose seamlessly","category":"section"},{"location":"#Contents","page":"Home","title":"Contents","text":"Pages = [\"tutorial.md\", \"examples.md\", \"api.md\", \"design.md\"]\nDepth = 2","category":"section"},{"location":"tutorial/#Tutorial","page":"Tutorial","title":"Tutorial","text":"","category":"section"},{"location":"tutorial/#Steps","page":"Tutorial","title":"Steps","text":"A Step is the basic unit of work—either a shell command or Julia function.","category":"section"},{"location":"tutorial/#Shell-Commands","page":"Tutorial","title":"Shell Commands","text":"# Direct command (anonymous step)\nstep = @step `samtools sort input.bam`\n\n# Named step\nstep = @step sort = `samtools sort input.bam`","category":"section"},{"location":"tutorial/#Julia-Functions","page":"Tutorial","title":"Julia Functions","text":"# Anonymous function step\nstep = @step () -> process_data()\n\n# Named function step\nstep = @step analyze = () -> run_analysis(\"data.csv\")","category":"section"},{"location":"tutorial/#File-Dependencies-(Optional)","page":"Tutorial","title":"File Dependencies (Optional)","text":"Track input/output files for validation:\n\n@step align(\"reads.fq\" => \"aligned.bam\") = `bwa mem ref.fa reads.fq > aligned.bam`","category":"section"},{"location":"tutorial/#Sequential-Execution:","page":"Tutorial","title":"Sequential Execution: >>","text":"The >> operator chains steps—each waits for the previous to complete:\n\n# Three steps in order\npipeline = step_a >> step_b >> step_c\n\n# Chain commands directly\npipeline = `download data.txt` >> `process data.txt` >> `upload results.txt`","category":"section"},{"location":"tutorial/#Parallel-Execution:-and","page":"Tutorial","title":"Parallel Execution: &","text":"The & operator groups steps to run concurrently:\n\n# Three steps in parallel\nparallel = step_a & step_b & step_c\n\n# Process samples in parallel, then merge\npipeline = (sample_1 & sample_2 & sample_3) >> merge_results","category":"section"},{"location":"tutorial/#Complex-DAGs","page":"Tutorial","title":"Complex DAGs","text":"Combine >> and & for arbitrary graphs.","category":"section"},{"location":"tutorial/#Diamond-Pattern","page":"Tutorial","title":"Diamond Pattern","text":"       ┌── analyze_a ──┐\n fetch─┤               ├── report\n       └── analyze_b ──┘\n\nfetch = @step fetch = `curl -o data.csv https://example.com/data`\nanalyze_a = @step a = `tool_a data.csv`\nanalyze_b = @step b = `tool_b data.csv`\nreport = @step report = () -> combine_results()\n\npipeline = fetch >> (analyze_a & analyze_b) >> report","category":"section"},{"location":"tutorial/#Multi-Stage-Parallel","page":"Tutorial","title":"Multi-Stage Parallel","text":"For graphs with multiple fork-join points, compose in stages:\n\n     ┌─ b ─┐     ┌─ e ─┐\n  a ─┤     ├─ d ─┤     ├─ g\n     └─ c ─┘     └─ f ─┘\n\na = @step a = `step_a`\nb = @step b = `step_b`\nc = @step c = `step_c`\nd = @step d = `step_d`\ne = @step e = `step_e`\nf = @step f = `step_f`\ng = @step g = `step_g`\n\npipeline = a >> (b & c) >> d >> (e & f) >> g","category":"section"},{"location":"tutorial/#Independent-Branches","page":"Tutorial","title":"Independent Branches","text":"Process independent pipelines in parallel, then merge:\n\n  ┌─ fetch_a >> process_a ─┐\n  │                        │\n  ├─ fetch_b >> process_b ─┼── merge\n  │                        │\n  └─ fetch_c >> process_c ─┘\n\nbranch_a = fetch_a >> process_a\nbranch_b = fetch_b >> process_b\nbranch_c = fetch_c >> process_c\n\npipeline = (branch_a & branch_b & branch_c) >> merge\n\nThis pattern is common for processing multiple samples/files independently before combining results.","category":"section"},{"location":"tutorial/#Running-Pipelines","page":"Tutorial","title":"Running Pipelines","text":"# Basic execution\nresults = run_pipeline(pipeline)\n\n# Silent (no progress output)\nresults = run_pipeline(pipeline, verbose=false)\n\n# Dry run (preview structure)\nrun_pipeline(pipeline, dry_run=true)\n\n# Named pipeline\np = Pipeline(step_a >> step_b, name=\"My Workflow\")\nrun_pipeline(p)","category":"section"},{"location":"tutorial/#Checking-Results","page":"Tutorial","title":"Checking Results","text":"results = run_pipeline(pipeline)\n\nfor r in results\n    if r.success\n        println(\"$(r.step.name): completed in $(r.duration)s\")\n    else\n        println(\"$(r.step.name): FAILED - $(r.output)\")\n    end\nend\n\n# Check overall success\nall_ok = all(r -> r.success, results)","category":"section"},{"location":"tutorial/#Mixing-Shell-and-Julia","page":"Tutorial","title":"Mixing Shell and Julia","text":"Shell commands and Julia functions compose seamlessly:\n\n# Julia: prepare data\nprep = @step prep = () -> begin\n    data = load(\"raw.csv\")\n    cleaned = filter_invalid(data)\n    save(\"clean.csv\", cleaned)\nend\n\n# Shell: run external tool\nexternal = @step tool = `external_program clean.csv -o result.txt`\n\n# Julia: postprocess\npost = @step post = () -> parse_and_summarize(\"result.txt\")\n\npipeline = prep >> external >> post\nrun_pipeline(pipeline)","category":"section"},{"location":"tutorial/#Utilities","page":"Tutorial","title":"Utilities","text":"# Count steps in a pipeline\nn = count_steps(pipeline)\n\n# Get all steps as a vector\nall_steps = steps(pipeline)\n\n# Print DAG structure\nprint_dag(pipeline)","category":"section"}]
}
