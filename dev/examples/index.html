<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Examples · SimplePipelines.jl</title><meta name="title" content="Examples · SimplePipelines.jl"/><meta property="og:title" content="Examples · SimplePipelines.jl"/><meta property="twitter:title" content="Examples · SimplePipelines.jl"/><meta name="description" content="Documentation for SimplePipelines.jl."/><meta property="og:description" content="Documentation for SimplePipelines.jl."/><meta property="twitter:description" content="Documentation for SimplePipelines.jl."/><meta property="og:url" content="https://mashu.github.io/SimplePipelines.jl/examples/"/><meta property="twitter:url" content="https://mashu.github.io/SimplePipelines.jl/examples/"/><link rel="canonical" href="https://mashu.github.io/SimplePipelines.jl/examples/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">SimplePipelines.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../tutorial/">Tutorial</a></li><li class="is-active"><a class="tocitem" href>Examples</a><ul class="internal"><li><a class="tocitem" href="#1.-Basics"><span>1. Basics</span></a></li><li><a class="tocitem" href="#2.-Control-flow"><span>2. Control flow</span></a></li><li><a class="tocitem" href="#3.-Complex-DAGs"><span>3. Complex DAGs</span></a></li><li><a class="tocitem" href="#4.-Bioinformatics"><span>4. Bioinformatics</span></a></li></ul></li><li><a class="tocitem" href="../api/">API Reference</a></li><li><a class="tocitem" href="../design/">Design</a></li><li><a class="tocitem" href="../development/">Development</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Examples</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Examples</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/mashu/SimplePipelines.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/mashu/SimplePipelines.jl/blob/main/docs/src/examples.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Examples"><a class="docs-heading-anchor" href="#Examples">Examples</a><a id="Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Examples" title="Permalink"></a></h1><p>This page shows pipeline patterns in order of increasing complexity. Each example has a flow diagram, a short goal, and runnable code.</p><p><strong>Contents</strong></p><ol><li><a href="#1-basics">Basics</a> — sequential, parallel, Julia + shell</li><li><a href="#2-control-flow">Control flow</a> — retry, fallback, branching</li><li><a href="#3-complex-dags">Complex DAGs</a> — multi-stage parallel, robust pipeline</li><li><a href="#4-bioinformatics">Bioinformatics</a> — immune repertoire (single &amp; multi-donor), variant calling</li></ol><hr/><h2 id="1.-Basics"><a class="docs-heading-anchor" href="#1.-Basics">1. Basics</a><a id="1.-Basics-1"></a><a class="docs-heading-anchor-permalink" href="#1.-Basics" title="Permalink"></a></h2><h3 id="1.1-Basic-Pipeline"><a class="docs-heading-anchor" href="#1.1-Basic-Pipeline">1.1 Basic Pipeline</a><a id="1.1-Basic-Pipeline-1"></a><a class="docs-heading-anchor-permalink" href="#1.1-Basic-Pipeline" title="Permalink"></a></h3><p><strong>Flow:</strong> Three steps in sequence.</p><pre><code class="nohighlight hljs">  download  ──►  process  ──►  upload</code></pre><p><strong>Goal:</strong> Create a file, process it, then copy the result (runnable without network).</p><pre><code class="language-julia hljs">using SimplePipelines

download = @step download = sh&quot;(echo line3; echo line1; echo line2) &gt; data.txt&quot;
process = @step process = sh&quot;sort data.txt &gt; sorted.txt&quot;
upload = @step upload = sh&quot;cp sorted.txt uploaded.txt&quot;

pipeline = download &gt;&gt; process &gt;&gt; upload
run(pipeline)</code></pre><hr/><h3 id="1.2-Parallel-Processing"><a class="docs-heading-anchor" href="#1.2-Parallel-Processing">1.2 Parallel Processing</a><a id="1.2-Parallel-Processing-1"></a><a class="docs-heading-anchor-permalink" href="#1.2-Parallel-Processing" title="Permalink"></a></h3><p><strong>Flow:</strong> Three steps run in parallel, then one step merges.</p><pre><code class="nohighlight hljs">       ┌── file_a ──┐
       ├── file_b ──┼──►  archive
       └── file_c ──┘</code></pre><p><strong>Goal:</strong> Create three files, compress them concurrently, then archive (runnable as-is).</p><pre><code class="language-julia hljs">using SimplePipelines

file_a = @step a = sh&quot;echo content_a &gt; file_a.txt &amp;&amp; gzip -k file_a.txt&quot;
file_b = @step b = sh&quot;echo content_b &gt; file_b.txt &amp;&amp; gzip -k file_b.txt&quot;
file_c = @step c = sh&quot;echo content_c &gt; file_c.txt &amp;&amp; gzip -k file_c.txt&quot;
archive = @step archive = sh&quot;tar -cvf archive.tar file_a.txt.gz file_b.txt.gz file_c.txt.gz&quot;

pipeline = (file_a &amp; file_b &amp; file_c) &gt;&gt; archive
run(pipeline)</code></pre><hr/><h3 id="1.3-Julia-Shell"><a class="docs-heading-anchor" href="#1.3-Julia-Shell">1.3 Julia + Shell</a><a id="1.3-Julia-Shell-1"></a><a class="docs-heading-anchor-permalink" href="#1.3-Julia-Shell" title="Permalink"></a></h3><p><strong>Flow:</strong> Julia step → shell step → Julia step.</p><pre><code class="nohighlight hljs">  generate  ──►  process  ──►  report
   (Julia)       (shell)      (Julia)</code></pre><p><strong>Goal:</strong> Generate data in Julia, run a shell tool, then summarize in Julia.</p><pre><code class="language-julia hljs">using SimplePipelines
using DelimitedFiles

generate = @step generate = () -&gt; begin
    data = rand(100, 10)
    writedlm(&quot;matrix.csv&quot;, data, &#39;,&#39;)
    return &quot;Generated $(size(data)) matrix&quot;
end

process = @step process = sh&quot;wc -l matrix.csv&quot;

report = @step report = () -&gt; begin
    lines = read(&quot;matrix.csv&quot;, String)
    nrows = count(==(&#39;\n&#39;), lines)
    return &quot;Matrix has $nrows rows&quot;
end

pipeline = generate &gt;&gt; process &gt;&gt; report
run(pipeline)</code></pre><hr/><h2 id="2.-Control-flow"><a class="docs-heading-anchor" href="#2.-Control-flow">2. Control flow</a><a id="2.-Control-flow-1"></a><a class="docs-heading-anchor-permalink" href="#2.-Control-flow" title="Permalink"></a></h2><h3 id="2.1-Retry-and-Fallback"><a class="docs-heading-anchor" href="#2.1-Retry-and-Fallback">2.1 Retry and Fallback</a><a id="2.1-Retry-and-Fallback-1"></a><a class="docs-heading-anchor-permalink" href="#2.1-Retry-and-Fallback" title="Permalink"></a></h3><p><strong>Flow (retry then continue):</strong> Run a step up to N times, then continue.</p><pre><code class="nohighlight hljs">  [fetch^3]  ──►  process
   (retry)</code></pre><p><strong>Flow (fallback):</strong> If primary fails, run fallback.</p><pre><code class="nohighlight hljs">   primary  ──►  (on success)  result
      │
      └──►  (on failure)  fallback  ──►  result</code></pre><p><strong>Goal:</strong> Retry flaky fetch; use fallback when primary step fails; combine retry and fallback.</p><pre><code class="language-julia hljs">using SimplePipelines

# Retry then continue (fetch creates file; no network)
fetch = @step fetch = sh&quot;echo &#39;{\&quot;x\&quot;:1}&#39; &gt; data.json&quot;
process = @step process = sh&quot;wc -c data.json&quot;
pipeline = Retry(fetch, 3, delay=0.1) &gt;&gt; process

# Fallback (create data.csv first so both branches have input)
run(@step setup = sh&quot;(echo &#39;a,b&#39;; echo &#39;1,2&#39;) &gt; data.csv&quot;, verbose=false)
fast = @step fast = sh&quot;sort data.csv &gt; sorted.csv&quot;
slow = @step slow = sh&quot;cat data.csv &gt; sorted.csv&quot;
pipeline = fast | slow

# Retry then fallback
pipeline = Retry(fast, 3) | slow
run(pipeline)</code></pre><hr/><h3 id="2.2-Conditional-Branching"><a class="docs-heading-anchor" href="#2.2-Conditional-Branching">2.2 Conditional Branching</a><a id="2.2-Conditional-Branching-1"></a><a class="docs-heading-anchor-permalink" href="#2.2-Conditional-Branching" title="Permalink"></a></h3><p><strong>Flow:</strong> One of two branches runs based on a condition.</p><pre><code class="nohighlight hljs">            ┌── if true  ──►  branch_a
  condition ─┤
            └── if false ──►  branch_b</code></pre><p><strong>Goal:</strong> Choose processing path by file size or environment (e.g. DEBUG).</p><pre><code class="language-julia hljs">using SimplePipelines

# Create data.csv so the branch condition has a file to check
run(@step setup = sh&quot;(echo &#39;a,b&#39;; echo &#39;1,2&#39;; echo &#39;3,4&#39;) &gt; data.csv&quot;, verbose=false)

# By file size
small_pipeline = @step small = sh&quot;head -n 1000 data.csv &gt; sample.csv&quot;
large_pipeline = @step decompress = sh&quot;gunzip -c data.csv.gz &gt; data.csv&quot; &gt;&gt; @step process = sh&quot;split -l 10000 data.csv chunk_&quot;
pipeline = Branch(
    () -&gt; filesize(&quot;data.csv&quot;) &lt; 100_000_000,
    small_pipeline,
    large_pipeline
)
run(pipeline)

# By environment
debug_steps = @step debug = sh&quot;echo &#39;debug mode&#39;&quot;
prod_steps = @step prod = sh&quot;echo &#39;production&#39;&quot;
pipeline = Branch(() -&gt; get(ENV, &quot;DEBUG&quot;, &quot;0&quot;) == &quot;1&quot;, debug_steps, prod_steps)
run(pipeline)</code></pre><hr/><h2 id="3.-Complex-DAGs"><a class="docs-heading-anchor" href="#3.-Complex-DAGs">3. Complex DAGs</a><a id="3.-Complex-DAGs-1"></a><a class="docs-heading-anchor-permalink" href="#3.-Complex-DAGs" title="Permalink"></a></h2><h3 id="3.1-Multi-stage-Parallel"><a class="docs-heading-anchor" href="#3.1-Multi-stage-Parallel">3.1 Multi-stage Parallel</a><a id="3.1-Multi-stage-Parallel-1"></a><a class="docs-heading-anchor-permalink" href="#3.1-Multi-stage-Parallel" title="Permalink"></a></h3><p><strong>Flow:</strong> Two parallel fetch+transform branches, then merge, analyze, then report and archive in parallel.</p><pre><code class="nohighlight hljs">  ┌── fetch_db   ──►  transform_db  ──┐
  │                                    ├──►  merge  ──►  analyze  ──►  ┌── report
  └── fetch_files ──►  transform_files ─┘                               └── archive</code></pre><p><strong>Goal:</strong> Fetch from two sources in parallel (here: create two files), process each, merge, analyze, then report and archive (runnable without network).</p><pre><code class="language-julia hljs">using SimplePipelines

fetch_db = @step db = sh&quot;echo &#39;{\&quot;db\&quot;:1}&#39; &gt; db_data.json&quot;
fetch_files = @step files = sh&quot;echo &#39;local_data&#39; &gt; local_data.txt&quot;

transform_db = @step transform_db = sh&quot;wc -c db_data.json &gt; db_size.txt&quot;
transform_files = @step transform_files = sh&quot;wc -c local_data.txt &gt; files_size.txt&quot;

merge = @step merge = sh&quot;cat db_size.txt files_size.txt &gt; merged.txt&quot;
analyze = @step analyze = sh&quot;wc -l merged.txt &gt; results.txt&quot;

report = @step report = sh&quot;cat results.txt&quot;
archive = @step archive = sh&quot;gzip -c merged.txt &gt; results.tar.gz&quot;

db_branch = fetch_db &gt;&gt; transform_db
files_branch = fetch_files &gt;&gt; transform_files
pipeline = (db_branch &amp; files_branch) &gt;&gt; merge &gt;&gt; analyze &gt;&gt; (report &amp; archive)

run(pipeline)</code></pre><hr/><h3 id="3.2-Robust-Pipeline-(all-features)"><a class="docs-heading-anchor" href="#3.2-Robust-Pipeline-(all-features)">3.2 Robust Pipeline (all features)</a><a id="3.2-Robust-Pipeline-(all-features)-1"></a><a class="docs-heading-anchor-permalink" href="#3.2-Robust-Pipeline-(all-features)" title="Permalink"></a></h3><p><strong>Flow:</strong> Retry+fallback fetch → conditional process (small vs full) → report and notify in parallel (notify with retry).</p><pre><code class="nohighlight hljs">  [primary^3 | backup]  ──►  [small? quick : full]  ──►  report
                                                      └── notify^2</code></pre><p><strong>Goal:</strong> Fetch with retry and fallback; branch on file size; run report and notify in parallel (runnable without network).</p><pre><code class="language-julia hljs">using SimplePipelines

primary_source = @step primary = sh&quot;echo &#39;{\&quot;status\&quot;:\&quot;ok\&quot;}&#39; &gt; data.json&quot;
backup_source = @step backup = sh&quot;echo &#39;{\&quot;status\&quot;:\&quot;fallback\&quot;}&#39; &gt; data.json&quot;
fetch = Retry(primary_source, 3, delay=0.1) | backup_source

quick_process = @step quick = sh&quot;wc -c data.json &gt; output.txt&quot;
full_process = @step parse = sh&quot;wc -l data.json &gt; output.txt&quot; &gt;&gt; @step validate = sh&quot;wc -c output.txt &gt;&gt; output.txt&quot;

process = Branch(
    () -&gt; filesize(&quot;data.json&quot;) &lt; 1_000_000,
    quick_process,
    full_process
)

report = @step report = sh&quot;cat output.txt&quot;
notify = @step notify = sh&quot;echo &#39;Pipeline done&#39;&quot;

pipeline = fetch &gt;&gt; process &gt;&gt; (report &amp; Retry(notify, 2))
run(Pipeline(pipeline, name=&quot;Robust ETL&quot;))</code></pre><hr/><h2 id="4.-Bioinformatics"><a class="docs-heading-anchor" href="#4.-Bioinformatics">4. Bioinformatics</a><a id="4.-Bioinformatics-1"></a><a class="docs-heading-anchor-permalink" href="#4.-Bioinformatics" title="Permalink"></a></h2><p><strong>Multiple donors / samples:</strong> Use <code>ForEach</code> with a <code>{wildcard}</code> pattern to automatically discover files and create parallel branches. The wildcard values propagate via normal Julia <code>$()</code> interpolation.</p><p><strong>Note:</strong> Examples below use real tool names (PEAR, IgBLAST, BWA, etc.). They are runnable only if those tools are installed and input files exist; otherwise use <code>echo</code> placeholders as in the <a href="https://github.com/mashu/SimplePipelines.jl/blob/main/examples/bioinformatics.jl">basic examples</a>.</p><h3 id="4.1-Immune-Repertoire-(single-donor)"><a class="docs-heading-anchor" href="#4.1-Immune-Repertoire-(single-donor)">4.1 Immune Repertoire (single donor)</a><a id="4.1-Immune-Repertoire-(single-donor)-1"></a><a class="docs-heading-anchor-permalink" href="#4.1-Immune-Repertoire-(single-donor)" title="Permalink"></a></h3><p><strong>Flow:</strong> Paired-end FASTQ → merge (PEAR) → FASTQ→FASTA → IgBLAST (V/D/J) → Julia filter by identity.</p><pre><code class="nohighlight hljs">  R1.fastq ──┐
             ├──►  pear  ──►  to_fasta  ──►  igblast  ──►  filter_identity  ──►  igblast_filtered.tsv
  R2.fastq ──┘</code></pre><p><strong>Goal:</strong> Merge paired-end reads, run IgBLAST with V/D/J references, filter rows by <code>v_identity</code> and <code>j_identity</code> &gt; 90% in Julia.</p><pre><code class="language-julia hljs">using SimplePipelines
using DelimitedFiles

pear = @step pear = sh&quot;pear -f R1.fastq -r R2.fastq -o merged&quot;
to_fasta = @step to_fasta = sh&quot;seqtk seq -A merged.assembled.fastq &gt; merged.assembled.fasta&quot;
igblast = @step igblast = sh&quot;igblastn -query merged.assembled.fasta -germline_db_V V.fasta -germline_db_D D.fasta -germline_db_J J.fasta -outfmt 7 -out igblast.tsv&quot;

filter_identity = @step filter_identity = () -&gt; begin
    data, header_row = readdlm(&quot;igblast.tsv&quot;, &#39;\t&#39;, header=true)
    header = vec(header_row)
    v_idx = findfirst(isequal(&quot;v_identity&quot;), header)
    j_idx = findfirst(isequal(&quot;j_identity&quot;), header)
    to_float(x) = something(tryparse(Float64, string(x)), 0.0)
    filtered = [r for r in eachrow(data) if to_float(r[v_idx]) &gt; 90.0 &amp;&amp; to_float(r[j_idx]) &gt; 90.0]
    writedlm(&quot;igblast_filtered.tsv&quot;, vcat(header&#39;, filtered), &#39;\t&#39;)
    return &quot;Filtered $(length(filtered)) sequences&quot;
end

pipeline = pear &gt;&gt; to_fasta &gt;&gt; igblast &gt;&gt; filter_identity
run(Pipeline(pipeline, name=&quot;Immune Repertoire&quot;))</code></pre><hr/><h3 id="4.2-Immune-Repertoire-(multiple-donors)"><a class="docs-heading-anchor" href="#4.2-Immune-Repertoire-(multiple-donors)">4.2 Immune Repertoire (multiple donors)</a><a id="4.2-Immune-Repertoire-(multiple-donors)-1"></a><a class="docs-heading-anchor-permalink" href="#4.2-Immune-Repertoire-(multiple-donors)" title="Permalink"></a></h3><p><strong>Flow:</strong> <code>ForEach</code> discovers files matching pattern → one parallel branch per donor.</p><pre><code class="nohighlight hljs">  ForEach(&quot;fastq/{donor}_R1.fq.gz&quot;)
       │
       ├── donor1: pear → fasta → igblast  ──┐
       ├── donor2: pear → fasta → igblast  ──┼── (parallel)
       └── donorN: pear → fasta → igblast  ──┘</code></pre><p><strong>Goal:</strong> Run the same pipeline for every donor; files discovered automatically.</p><pre><code class="language-julia hljs">using SimplePipelines

# ForEach: pattern discovery + parallel branches in one construct
pipeline = ForEach(&quot;fastq/{donor}_R1.fq.gz&quot;) do donor
    sh(&quot;pear -f fastq/$(donor)_R1.fq.gz -r fastq/$(donor)_R2.fq.gz -o $(donor)_merged&quot;) &gt;&gt;
    sh(&quot;seqtk seq -A $(donor)_merged.assembled.fastq &gt; $(donor).fasta&quot;) &gt;&gt;
    sh(&quot;igblastn -query $(donor).fasta -germline_db_V V.fasta -germline_db_D D.fasta -germline_db_J J.fasta -outfmt 7 -out $(donor)_igblast.tsv&quot;)
end

run(pipeline)</code></pre><hr/><h3 id="4.3-Variant-Calling"><a class="docs-heading-anchor" href="#4.3-Variant-Calling">4.3 Variant Calling</a><a id="4.3-Variant-Calling-1"></a><a class="docs-heading-anchor-permalink" href="#4.3-Variant-Calling" title="Permalink"></a></h3><p><strong>Flow:</strong> Paired-end reads → FastQC → trim → BWA (GRCh38) → sort/index → bcftools call → index → filter.</p><pre><code class="nohighlight hljs">  R1.fq.gz ──┐
             ├──►  fastqc  ──►  trim  ──►  align  ──►  index  ──►  call  ──►  index_vcf  ──►  filter_vcf
  R2.fq.gz ──┘</code></pre><p><strong>Goal:</strong> QC, trim, align to GRCh38, call variants with bcftools, filter by quality.</p><pre><code class="language-julia hljs">using SimplePipelines

fastqc = @step fastqc = sh&quot;fastqc -o qc/ R1.fq.gz R2.fq.gz&quot;
trim = @step trim = sh&quot;trimmomatic PE R1.fq.gz R2.fq.gz R1_trimmed.fq.gz R1_unpaired.fq.gz R2_trimmed.fq.gz R2_unpaired.fq.gz ILLUMINACLIP:adapters.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36&quot;

align = @step align = sh&quot;bwa mem -t 8 GRCh38.fa R1_trimmed.fq.gz R2_trimmed.fq.gz | samtools sort -@ 4 -o aligned.bam -&quot;
index = @step index = sh&quot;samtools index aligned.bam&quot;

call = @step call = sh&quot;bcftools mpileup -f GRCh38.fa aligned.bam | bcftools call -mv -Oz -o variants.vcf.gz&quot;
index_vcf = @step index_vcf = sh&quot;bcftools index variants.vcf.gz&quot;
filter_vcf = @step filter_vcf = sh&quot;bcftools filter -i &#39;QUAL&gt;=20&#39; variants.vcf.gz -Oz -o filtered.vcf.gz&quot;

pipeline = fastqc &gt;&gt; trim &gt;&gt; align &gt;&gt; index &gt;&gt; call &gt;&gt; index_vcf &gt;&gt; filter_vcf
run(Pipeline(pipeline, name=&quot;Variant Calling&quot;))</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../tutorial/">« Tutorial</a><a class="docs-footer-nextpage" href="../api/">API Reference »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Friday 13 February 2026 17:02">Friday 13 February 2026</span>. Using Julia version 1.12.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
